{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Classify Fruits and Vegetables</u>\n",
    "### Dataset: Fruits360\n",
    "\n",
    "- Then to build an iOS app to use the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "import os\n",
    "from io import open\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "transforms_train = T.Compose([T.ToTensor(),T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "image_data_train = ImageFolder(\"./Fruit-Images-Dataset/data\",transform=transforms_train)\n",
    "image_data_test = ImageFolder(\"./Fruit-Images-Dataset/Test2\",transform=transforms_train)\n",
    "\n",
    "\n",
    "\n",
    "# Shuffling data and then collecting all the labels.\n",
    "random.shuffle(image_data_train.samples)\n",
    "random.shuffle(image_data_test.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total classes\n",
    "classes_idx = image_data_train.class_to_idx\n",
    "classes = len(image_data_train.classes)\n",
    "len_train_data = len(image_data_train)\n",
    "len_test_data = len(image_data_test)\n",
    "\n",
    "\n",
    "\n",
    "def get_labels():\n",
    "    labels_train = [] # All the labels\n",
    "    labels_test = []\n",
    "    for i in image_data_train.imgs:\n",
    "        labels_train.append(i[1])\n",
    "    \n",
    "    for j in image_data_test.imgs:\n",
    "        labels_test.append(j[1])\n",
    "    \n",
    "    return (labels_train, labels_test)\n",
    "\n",
    "labels_train, labels_test = get_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=image_data_train,batch_size=100)\n",
    "test_loader = DataLoader(dataset=image_data_test,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "print (iter(train_loader).next()[0].shape)\n",
    "record = iter(train_loader).next()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the image is (batch_size, channel, image_height, image_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Layer\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "# Main Model\n",
    "class Model:\n",
    "    def build_model(self):\n",
    "        model = nn.Sequential(nn.Conv2d(3, 64, kernel_size=5, stride=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool2d(2),\n",
    "                              nn.Conv2d(64, 64, kernel_size=7, stride=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool2d(3),\n",
    "                              nn.Conv2d(64, 64, kernel_size=7),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool2d(5),\n",
    "                              Flatten(),\n",
    "                              nn.Linear(64, 100),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Linear(100, 65))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Flatten()\n",
       "  (10): Linear(in_features=64, out_features=100, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Linear(in_features=100, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building \n",
    "model = Model()\n",
    "model = model.build_model()\n",
    "\n",
    "# Checking for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (7): ReLU()\n",
      "  (8): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Flatten()\n",
      "  (10): Linear(in_features=64, out_features=100, bias=True)\n",
      "  (11): ReLU()\n",
      "  (12): Linear(in_features=100, out_features=65, bias=True)\n",
      ")\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print (model)\n",
    "print (labels_train[0])\n",
    "print (image_data_train.samples[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train(epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print (\"epoch #\", epoch)\n",
    "        current_loss = 0.0\n",
    "        for feature, label in train_loader:\n",
    "            x = Variable(feature, requires_grad=False).float().to(device)\n",
    "            y = Variable(label, requires_grad=False).long().to(device)\n",
    "            optimizer.zero_grad() # Zeroing the grads\n",
    "            y_pred = model(x) # Calculating prediction\n",
    "            correct = y_pred.max(1)[1].eq(y).sum()\n",
    "            print (\"no. of correct items classified: \", correct.item())\n",
    "            loss = criterion(y_pred, y) # Calculating loss (log_softmax already included)\n",
    "            print (\"loss: \", loss.item())\n",
    "            current_loss+=loss.item()\n",
    "            loss.backward() # Gradient cal\n",
    "            optimizer.step() # Changing weights\n",
    "        losses.append(current_loss) # Only storing loss after every epoch\n",
    "    return losses\n",
    "# Test the model\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for feature, label in test_loader:\n",
    "            pred = model(feature)\n",
    "            print (\"acc: \", accuracy_score(labels_test, pred.max(1)[1].data.numpy()) * 100)\n",
    "            loss = criterion(pred, label)\n",
    "            print (\"loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Flatten()\n",
       "  (10): Linear(in_features=64, out_features=100, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Linear(in_features=100, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_state_dict = torch.load(\"./model-state-dict.pth\",map_location=\"cpu\")\n",
    "# model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(load_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Flatten()\n",
       "  (10): Linear(in_features=64, out_features=100, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Linear(in_features=100, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(imagefile):\n",
    "    print(\"Prediction in progress\")\n",
    "    \n",
    "    imagepath = os.path.join(os.getcwd(), imagefile)\n",
    "    image = Image.open(imagepath)\n",
    "\n",
    "    # Define transformations for the image, should (note that imagenet models are trained with image size 224)\n",
    "    transformation = transforms.Compose([\n",
    "#         transforms.CenterCrop(100),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = transformation(image).float()\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all images as batches\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    output = model(input)\n",
    "\n",
    "    index = output.data.numpy().argmax()\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction in progress\n"
     ]
    }
   ],
   "source": [
    "abc = predict_image(\"Tomato2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "print(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple Braeburn': 0, 'Apple Crimson Snow': 1, 'Apple Golden 1': 2, 'Apple Golden 2': 3, 'Apple Golden 3': 4, 'Apple Granny Smith': 5, 'Apple Pink Lady': 6, 'Apple Red 1': 7, 'Apple Red 2': 8, 'Apple Red 3': 9, 'Apple Red Delicious': 10, 'Apple Red Yellow 1': 11, 'Apple Red Yellow 2': 12, 'Apricot': 13, 'Avocado': 14, 'Avocado ripe': 15, 'Banana': 16, 'Banana Lady Finger': 17, 'Banana Red': 18, 'Beetroot': 19, 'Blueberry': 20, 'Cactus fruit': 21, 'Cantaloupe 1': 22, 'Cantaloupe 2': 23, 'Carambula': 24, 'Cauliflower': 25, 'Cherry 1': 26, 'Cherry 2': 27, 'Cherry Rainier': 28, 'Cherry Wax Black': 29, 'Cherry Wax Red': 30, 'Cherry Wax Yellow': 31, 'Chestnut': 32, 'Clementine': 33, 'Cocos': 34, 'Dates': 35, 'Eggplant': 36, 'Ginger Root': 37, 'Granadilla': 38, 'Grape Blue': 39, 'Grape Pink': 40, 'Grape White': 41, 'Grape White 2': 42, 'Grape White 3': 43, 'Grape White 4': 44, 'Grapefruit Pink': 45, 'Grapefruit White': 46, 'Guava': 47, 'Hazelnut': 48, 'Huckleberry': 49, 'Kaki': 50, 'Kiwi': 51, 'Kohlrabi': 52, 'Kumquats': 53, 'Lemon': 54, 'Lemon Meyer': 55, 'Limes': 56, 'Lychee': 57, 'Mandarine': 58, 'Mango': 59, 'Mango Red': 60, 'Mangostan': 61, 'Maracuja': 62, 'Melon Piel de Sapo': 63, 'Mulberry': 64, 'Nectarine': 65, 'Nectarine Flat': 66, 'Nut Forest': 67, 'Nut Pecan': 68, 'Onion Red': 69, 'Onion Red Peeled': 70, 'Onion White': 71, 'Orange': 72, 'Papaya': 73, 'Passion Fruit': 74, 'Peach': 75, 'Peach 2': 76, 'Peach Flat': 77, 'Pear': 78, 'Pear Abate': 79, 'Pear Forelle': 80, 'Pear Kaiser': 81, 'Pear Monster': 82, 'Pear Red': 83, 'Pear Williams': 84, 'Pepino': 85, 'Pepper Green': 86, 'Pepper Red': 87, 'Pepper Yellow': 88, 'Physalis': 89, 'Physalis with Husk': 90, 'Pineapple': 91, 'Pineapple Mini': 92, 'Pitahaya Red': 93, 'Plum': 94, 'Plum 2': 95, 'Plum 3': 96, 'Pomegranate': 97, 'Pomelo Sweetie': 98, 'Potato Red': 99, 'Potato Red Washed': 100, 'Potato Sweet': 101, 'Potato White': 102, 'Quince': 103, 'Rambutan': 104, 'Raspberry': 105, 'Redcurrant': 106, 'Salak': 107, 'Strawberry': 108, 'Strawberry Wedge': 109, 'Tamarillo': 110, 'Tangelo': 111, 'Tomato 1': 112, 'Tomato 2': 113, 'Tomato 3': 114, 'Tomato 4': 115, 'Tomato Cherry Red': 116, 'Tomato Maroon': 117, 'Tomato Yellow': 118, 'Walnut': 119}\n"
     ]
    }
   ],
   "source": [
    "print(classes_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
